<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>消息队列NSQ源码分析（四）：nsqlookupd</title>
      <link href="/2020/04/14/nsq-3/"/>
      <url>/2020/04/14/nsq-3/</url>
      
        <content type="html"><![CDATA[<p>本篇为NSQ源码分析的第四篇，主要分析nsq服务端发现机制的源码，即nsqlookupd</p><a id="more"></a><h2 id="概述">概述</h2><p>nsqlookupd主要用来管理生产者实例（即nsqd）的注册与发现。nsqd实例启动时可以指定nsqlookupd实例地址，启动后会以一定时间间隔上报实例信息到nsqlookupd。消费者客户端通过查询nsqlookupd即可实现动态发现当前生产指定topic的nsqd实例。下面我们将从启动过程、生产者注册、生产者发现等3个模块来讲述nsqlookupd的具体实现。</p><h2 id="启动过程">启动过程</h2><p>我们从<code>apps/nsqlookupd/main.go</code>开始，可以看到其代码结构与之前的nsqd类似，使用了program包装，同时实现了Init、Start、Stop等方法，具体看下Start方法的执行过程：</p><pre><code class="language-go">func (p *program) Start() error {opts := nsqlookupd.NewOptions()flagSet := nsqlookupdFlagSet(opts)flagSet.Parse(os.Args[1:])var cfg map[string]interface{}configFile := flagSet.Lookup(&quot;config&quot;).Value.String()if configFile != &quot;&quot; {_, err := toml.DecodeFile(configFile, &amp;cfg)if err != nil {logFatal(&quot;failed to load config file %s - %s&quot;, configFile, err)}}options.Resolve(opts, flagSet, cfg)nsqlookupd, err := nsqlookupd.New(opts)if err != nil {logFatal(&quot;failed to instantiate nsqlookupd&quot;, err)}p.nsqlookupd = nsqlookupdgo func() {err := p.nsqlookupd.Main()if err != nil {p.Stop()os.Exit(1)}}()return nil}</code></pre><p>大致流程仍然与nsqd类似：解析启动参数，创建nsqlookupd实例、执行nsqlookupd实例的Main函数，接着我们看下nsqlookupd.New与nsqlookupd.Main两个函数：</p><pre><code class="language-go">func New(opts *Options) (*NSQLookupd, error) {var err errorif opts.Logger == nil {opts.Logger = log.New(os.Stderr, opts.LogPrefix, log.Ldate|log.Ltime|log.Lmicroseconds)}l := &amp;NSQLookupd{opts: opts,DB:   NewRegistrationDB(),}l.logf(LOG_INFO, version.String(&quot;nsqlookupd&quot;))l.tcpListener, err = net.Listen(&quot;tcp&quot;, opts.TCPAddress)if err != nil {return nil, fmt.Errorf(&quot;listen (%s) failed - %s&quot;, opts.TCPAddress, err)}l.httpListener, err = net.Listen(&quot;tcp&quot;, opts.HTTPAddress)if err != nil {return nil, fmt.Errorf(&quot;listen (%s) failed - %s&quot;, opts.TCPAddress, err)}return l, nil}</code></pre><p>nsqlookupd.New用来根据启动参数创建nsqd实例，同时开启tcp、http两个端口监听，接着我们看下nsqlookupd.Main的内容：</p><pre><code class="language-go">func (l *NSQLookupd) Main() error {ctx := &amp;Context{l}exitCh := make(chan error)var once sync.OnceexitFunc := func(err error) {once.Do(func() {if err != nil {l.logf(LOG_FATAL, &quot;%s&quot;, err)}exitCh &lt;- err})}tcpServer := &amp;tcpServer{ctx: ctx}l.waitGroup.Wrap(func() {exitFunc(protocol.TCPServer(l.tcpListener, tcpServer, l.logf))})httpServer := newHTTPServer(ctx)l.waitGroup.Wrap(func() {exitFunc(http_api.Serve(l.httpListener, httpServer, &quot;HTTP&quot;, l.logf))})err := &lt;-exitChreturn err}</code></pre><p>通过上述代码可以看出，nsqlookupd.Main主要包含逻辑有：<br>1、开启单独协程对tcp连接进行处理<br>2、开启单独协程对http连接进行处理</p><h2 id="生产者注册">生产者注册</h2><p>生产者实例信息注册通过tcp连接通信来完成，关于连接处理、通信这一块大致的流程与nsqd类似，主要就是接受nsqd发送过来的信息，这些信息主要包括topic、channel、nsqd实例地址、tcp端口号、http端口号等，然后nsqlookupd会将这些信息放置在内存中的一个RegistrationDB结构中并维护，具体实现代码在<code>nsqlookupd/lookup_protocol_v1.go</code>与<code>registration_db.go</code>中，因整个过程实现较为简单，有兴趣的同学可以直接查看源码，这里就不再详细描述了。</p><h2 id="生产者发现">生产者发现</h2><p>生产者的发现则是通过http接口查询上述RegistrationDB结构中的信息来实现，消费者客户端会定时轮询该http接口以支持动态发现生产指定topic的nsqd实例，具体实现代码可查看<code>nsqlookupd/http.go</code>。</p>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nsq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列NSQ源码分析（三）：nsqd</title>
      <link href="/2020/04/14/nsq-2/"/>
      <url>/2020/04/14/nsq-2/</url>
      
        <content type="html"><![CDATA[<p>本篇为NSQ源码分析的第三篇，主要分析nsq的服务端源码，即nsqd</p><a id="more"></a><h2 id="启动过程">启动过程</h2><p>首先看一下nsqd的启动过程，我们从<code>apps/nsqd/main.go</code>开始，可以看到在main包中声明了<code>program</code>结构体，该结构体包装了nsqd实例，提供了Init、Start、Stop方法。接着我们看main函数，主要逻辑就是创建program结构体，然后调用<code>github.com/judwhite/go-svc</code>这个库提供的svc.Run方法，该方法底层实现则是调用program的Init、Start方法，引入这个库主要是为了提供创建可在其自身的 Windows 会话中长时间运行的可执行应用程序的支持。现在我们重点看下program的Start方法，简化后的逻辑如下：</p><pre><code class="language-go">func (p *program) Start() error {opts := nsqd.NewOptions()flagSet := nsqdFlagSet(opts)flagSet.Parse(os.Args[1:])options.Resolve(opts, flagSet, cfg)nsqd, err := nsqd.New(opts)if err != nil {logFatal(&quot;failed to instantiate nsqd - %s&quot;, err)}p.nsqd = nsqderr = p.nsqd.LoadMetadata()if err != nil {logFatal(&quot;failed to load metadata - %s&quot;, err)}err = p.nsqd.PersistMetadata()if err != nil {logFatal(&quot;failed to persist metadata - %s&quot;, err)}go func() {err := p.nsqd.Main()if err != nil {p.Stop()os.Exit(1)}}()return nil}</code></pre><p>大致流程即为解析启动参数、创建nsqd实例、加载之前持久化的元数据（topic、channel等）、执行nsqd实例的main函数，接着我们看下nsqd.New与nsqd.Main两个函数：</p><pre><code class="language-go">func New(opts *Options) (*NSQD, error) {var err errorn := &amp;NSQD{startTime:            time.Now(),topicMap:             make(map[string]*Topic),clients:              make(map[int64]Client),exitChan:             make(chan int),notifyChan:           make(chan interface{}),optsNotificationChan: make(chan struct{}, 1),dl:                   dirlock.New(dataPath),}httpcli := http_api.NewClient(nil, opts.HTTPClientConnectTimeout, opts.HTTPClientRequestTimeout)n.ci = clusterinfo.New(n.logf, httpcli)n.lookupPeers.Store([]*lookupPeer{})n.swapOpts(opts)n.errValue.Store(errStore{})err = n.dl.Lock()if err != nil {return nil, fmt.Errorf(&quot;--data-path=%s in use (possibly by another instance of nsqd)&quot;, dataPath)}n.tcpListener, err = net.Listen(&quot;tcp&quot;, opts.TCPAddress)if err != nil {return nil, fmt.Errorf(&quot;listen (%s) failed - %s&quot;, opts.TCPAddress, err)}n.httpListener, err = net.Listen(&quot;tcp&quot;, opts.HTTPAddress)if err != nil {return nil, fmt.Errorf(&quot;listen (%s) failed - %s&quot;, opts.HTTPAddress, err)}if n.tlsConfig != nil &amp;&amp; opts.HTTPSAddress != &quot;&quot; {n.httpsListener, err = tls.Listen(&quot;tcp&quot;, opts.HTTPSAddress, n.tlsConfig)if err != nil {return nil, fmt.Errorf(&quot;listen (%s) failed - %s&quot;, opts.HTTPSAddress, err)}}return n, nil}</code></pre><p>nsqd.New用来根据启动参数创建nsqd实例，同时开启tcp、http两个端口监听，接着我们看下nsqd.Main的内容：</p><pre><code class="language-go">func (n *NSQD) Main() error {ctx := &amp;context{n}exitCh := make(chan error)var once sync.OnceexitFunc := func(err error) {once.Do(func() {if err != nil {n.logf(LOG_FATAL, &quot;%s&quot;, err)}exitCh &lt;- err})}tcpServer := &amp;tcpServer{ctx: ctx}n.waitGroup.Wrap(func() {exitFunc(protocol.TCPServer(n.tcpListener, tcpServer, n.logf))})httpServer := newHTTPServer(ctx, false, n.getOpts().TLSRequired == TLSRequired)n.waitGroup.Wrap(func() {exitFunc(http_api.Serve(n.httpListener, httpServer, &quot;HTTP&quot;, n.logf))})if n.tlsConfig != nil &amp;&amp; n.getOpts().HTTPSAddress != &quot;&quot; {httpsServer := newHTTPServer(ctx, true, true)n.waitGroup.Wrap(func() {exitFunc(http_api.Serve(n.httpsListener, httpsServer, &quot;HTTPS&quot;, n.logf))})}n.waitGroup.Wrap(n.queueScanLoop)n.waitGroup.Wrap(n.lookupLoop)if n.getOpts().StatsdAddress != &quot;&quot; {n.waitGroup.Wrap(n.statsdLoop)}err := &lt;-exitChreturn err}</code></pre><p>通过上述代码可以看出，nsqd.Main主要包含逻辑有：<br>1、开启单独协程对tcp连接进行处理<br>2、开启单独协程对http连接进行处理<br>3、如果存在https设置，则开启单独协程处理https请求<br>4、开启单独协程执行queueScanLoop，主要用来处理延迟消息以及超时消息，文章后面讲投递消息时会详细描述<br>5、开启单独协程执行lookupLoop，主要用来与nsqlookupd通信，保持心跳、上报数据等<br>6、如果配置了StatsdAddress，则开启单独协程执行statsdLoop，主要用来上报内存分配、gc、topic和channel等数据</p><h2 id="客户端连接处理、通信协议">客户端连接处理、通信协议</h2><p>现在我们来了解一下nsqd实例处理客户端连接的具体过程，上面Main中的代码可以看到，nsqd在tcp连接处理这一块采用的还是go语言中常规的网络模型，即调用accept接收连接，单独开启协程处理该连接，我们从tcp.go中的Handle方法开始，看看连接的具体处理过程：</p><pre><code class="language-go">func (p *tcpServer) Handle(clientConn net.Conn) {buf := make([]byte, 4)_, err := io.ReadFull(clientConn, buf)if err != nil {p.ctx.nsqd.logf(LOG_ERROR, &quot;failed to read protocol version - %s&quot;, err)clientConn.Close()return}protocolMagic := string(buf)p.ctx.nsqd.logf(LOG_INFO, &quot;CLIENT(%s): desired protocol magic '%s'&quot;,clientConn.RemoteAddr(), protocolMagic)var prot protocol.Protocolswitch protocolMagic {case &quot;  V2&quot;:prot = &amp;protocolV2{ctx: p.ctx}default:protocol.SendFramedResponse(clientConn, frameTypeError, []byte(&quot;E_BAD_PROTOCOL&quot;))clientConn.Close()p.ctx.nsqd.logf(LOG_ERROR, &quot;client(%s) bad protocol magic '%s'&quot;,clientConn.RemoteAddr(), protocolMagic)return}err = prot.IOLoop(clientConn)if err != nil {p.ctx.nsqd.logf(LOG_ERROR, &quot;client(%s) - %s&quot;, clientConn.RemoteAddr(), err)return}}</code></pre><p>可以看到，处理过程首先会读取4个字节的版本号，并判断当前协议版本是否为V2，不是的话则终止连接，接着创建protocolV2实例，调用IOLoop进入客户端连接的读写循环，我们再看下IOLoop的具体代码：</p><pre><code class="language-go">func (p *protocolV2) IOLoop(conn net.Conn) error {var err errorvar line []bytevar zeroTime time.TimeclientID := atomic.AddInt64(&amp;p.ctx.nsqd.clientIDSequence, 1)client := newClientV2(clientID, conn, p.ctx)p.ctx.nsqd.AddClient(client.ID, client)messagePumpStartedChan := make(chan bool)go p.messagePump(client, messagePumpStartedChan)&lt;-messagePumpStartedChanfor {if client.HeartbeatInterval &gt; 0 {client.SetReadDeadline(time.Now().Add(client.HeartbeatInterval * 2))} else {client.SetReadDeadline(zeroTime)}// ReadSlice does not allocate new space for the data each request// ie. the returned slice is only valid until the next call to itline, err = client.Reader.ReadSlice('\n')if err != nil {if err == io.EOF {err = nil} else {err = fmt.Errorf(&quot;failed to read command - %s&quot;, err)}break}// trim the '\n'line = line[:len(line)-1]// optionally trim the '\r'if len(line) &gt; 0 &amp;&amp; line[len(line)-1] == '\r' {line = line[:len(line)-1]}params := bytes.Split(line, separatorBytes)p.ctx.nsqd.logf(LOG_DEBUG, &quot;PROTOCOL(V2): [%s] %s&quot;, client, params)var response []byteresponse, err = p.Exec(client, params)if err != nil {ctx := &quot;&quot;if parentErr := err.(protocol.ChildErr).Parent(); parentErr != nil {ctx = &quot; - &quot; + parentErr.Error()}p.ctx.nsqd.logf(LOG_ERROR, &quot;[%s] - %s%s&quot;, client, err, ctx)sendErr := p.Send(client, frameTypeError, []byte(err.Error()))if sendErr != nil {p.ctx.nsqd.logf(LOG_ERROR, &quot;[%s] - %s%s&quot;, client, sendErr, ctx)break}// errors of type FatalClientErr should forceably close the connectionif _, ok := err.(*protocol.FatalClientErr); ok {break}continue}if response != nil {err = p.Send(client, frameTypeResponse, response)if err != nil {err = fmt.Errorf(&quot;failed to send response - %s&quot;, err)break}}}p.ctx.nsqd.logf(LOG_INFO, &quot;PROTOCOL(V2): [%s] exiting ioloop&quot;, client)conn.Close()close(client.ExitChan)if client.Channel != nil {client.Channel.RemoveClient(client.ID)}p.ctx.nsqd.RemoveClient(client.ID)return err}</code></pre><p>IOLoop的主要逻辑即为循环读取客户端发送的命令并执行，然后给客户端返回响应，需要注意的是，代码中单独开启了一个协程执行messagePump，该方法主要承担接收消息并分发给客户端、向客户端发送心跳包等功能</p><h2 id="接收消息">接收消息</h2><p>接收消息的过程由客户端发送PUB命令开始，然后再由protocol_v2.go中的IOLoop中读取命令并执行，PUB命令的具体执行过程大致如下：<br>1、解析PUB命令参数，得到topic名称以及消息内容<br>2、根据topic名称获取topic实例，调用topic.PutMessage发送消息，PutMessage方法实现上则是往topic内部的消息管道（memoryMsgChan）中发送消息</p><h2 id="投递消息">投递消息</h2><h3 id="直接投递">直接投递</h3><p>之前我们讲解了nsq中存在的Topic和Channel等概念，因此一条消息的投递会先由Topic分发给Channel，然后再由Channel到client，我们分别看下这两个投递过程</p><p>1、Topic -&gt; Channel，每个Topic创建出来的时候（NewTopic方法）都会开启一个额外的协程执行messagePump，我们看看该方法的具体逻辑：</p><pre><code class="language-go">func (t *Topic) messagePump() {t.RLock()for _, c := range t.channelMap {chans = append(chans, c)}t.RUnlock()for {select {case msg = &lt;-memoryMsgChan:case buf = &lt;-backendChan:msg, err = decodeMessage(buf)if err != nil {t.ctx.nsqd.logf(LOG_ERROR, &quot;failed to decode message - %s&quot;, err)continue}}for i, channel := range chans {chanMsg := msgif i &gt; 0 {chanMsg = NewMessage(msg.ID, msg.Body)chanMsg.Timestamp = msg.TimestampchanMsg.deferred = msg.deferred}if chanMsg.deferred != 0 {channel.PutMessageDeferred(chanMsg, chanMsg.deferred)continue}err := channel.PutMessage(chanMsg)if err != nil {t.ctx.nsqd.logf(LOG_ERROR,&quot;TOPIC(%s) ERROR: failed to put msg(%s) to channel(%s) - %s&quot;,t.name, msg.ID, channel.name, err)}}}exit:t.ctx.nsqd.logf(LOG_INFO, &quot;TOPIC(%s): closing ... messagePump&quot;, t.name)}</code></pre><p>上面代码经过简化后，只保留了与消息投递有关的代码，可以看到messagePump方法会一直从Topic的消息管道中读取消息，然后将消息分发给当前所有的Channel</p><p>2、channel -&gt; client，第一步中topic将消息分发给Channel，实现上是Channel会将消息发给自己的内部管道memoryMsgChan，客户端会从该消息管道中读取消息，从而到达消息分发的目的，具体代码可以看protocol_v2.go中的messagePump方法</p><h3 id="延迟投递">延迟投递</h3><p>nsq中支持了消息的延迟投递，我们来看看具体实现的逻辑：<br>1、每个Topic对应的Channel内部结构中存在一个优先级队列（Channel.deferredPQ，具体实现为最小堆），通过DeferredPublish发送的延迟消息首先会进入到Channel的优先级队列中，队列中每个元素的优先级具体值为延迟的时间<br>2、nsqd启动时有个queueScanLoop函数，这个函数每隔一定的时间间隔（配置项：QueueScanInterval）会拿到当前所有的channel，取一部分（配置项：QueueScanSelectionCount）进行扫描，并调用Channel的processDeferredQueue方法，processDeferredQueue方法则用来处理延迟消息，会从其对应的优先级队列中取出比当前时间小的那些消息进行发送，发送的过程跟上述的直接投递过程一样，这里就不细讲了</p><h3 id="超时处理">超时处理</h3><p>nsq中的消息投递模型为至少一次，那么就需要引入超时重传与确认机制，我们接着具体看看nsq是如何处理超时消息的：<br>1、与延迟投递类似，每个Topic对应的Channel内部结构中还存在另一个优先级队列（Channel.inFlightPQ），发送给客户端且还未收到处理结果的消息会存放在队列中，元素的优先级具体值为消息超时的时间<br>2、上面将延迟投递的时候，有讲到queueScanLoop这个函数，此函数在扫描Channel过程中也会调用Channel的processInFlightQueue方法，processInFlightQueue则会处理Channel中的超时消息，将这些超时消息取出来重新投递</p><h3 id="流量控制">流量控制</h3><p>关于流量控制这一块我们在上一篇讲消费者客户端的时候已经有所描述，即通过发送RDY状态来限制客户端的消息接收，下面我们就来看看nsqd实例在接收客户端发送的RDY值之后会有哪些变化，具体代码就在<code>nsqd/protocol_v2.go</code>中：</p><pre><code class="language-go">func (p *protocolV2) RDY(client *clientV2, params [][]byte) ([]byte, error) {count := int64(1)if len(params) &gt; 1 {b10, err := protocol.ByteToBase10(params[1])if err != nil {return nil, protocol.NewFatalClientErr(err, &quot;E_INVALID&quot;,fmt.Sprintf(&quot;RDY could not parse count %s&quot;, params[1]))}count = int64(b10)}if count &lt; 0 || count &gt; p.ctx.nsqd.getOpts().MaxRdyCount {// this needs to be a fatal error otherwise clients would have// inconsistent statereturn nil, protocol.NewFatalClientErr(nil, &quot;E_INVALID&quot;,fmt.Sprintf(&quot;RDY count %d out of range 0-%d&quot;, count, p.ctx.nsqd.getOpts().MaxRdyCount))}client.SetReadyCount(count)return nil, nil}</code></pre><p>当nsqd接收到客户端发送的RDY命令时，会调用client.SetReadyCount(count)方法，将该客户端ReadyCount设置为count，当客户端触发流量控制时，count即为0，接着我们看投递消息给客户端时的处理逻辑：</p><pre><code class="language-go">func (p *protocolV2) messagePump(client *clientV2, startedChan chan bool) {for {if subChannel == nil || !client.IsReadyForMessages() {// the client is not ready to receive messages...memoryMsgChan = nilbackendMsgChan = nilflusherChan = nil// force flushclient.writeLock.Lock()err = client.Flush()client.writeLock.Unlock()if err != nil {goto exit}flushed = true}            select {        case &lt;-client.ReadyStateChan:        case &lt;-heartbeatChan:        case b := &lt;-backendMsgChan:        case msg := &lt;-memoryMsgChan:        }}}</code></pre><p>这里我将messagePump其他逻辑都屏蔽掉了，想要突出的是if条件判断中的<code>!client.IsReadyForMessages()</code>，当消费者客户端进行流量控制时，会将RDY置为0，此时client的IsReadyForMessages则返回false，整个条件判断逻辑也就为true，然后执行if块中的代码，即将memoryMsgChan和backendMsgChan设置为nil，置为nil后代码之后的select逻辑也就无法从消息管道中获取消息，从而达到限制该客户端接收消息的目的</p><h2 id="持久化">持久化</h2><p>nsq目前有两块持久化数据的逻辑：<br>1、当nsqd实例存在topic、channel新建、删除等元数据变化的时候，会进行持久化，具体方法可见nsqd.PersistMetadata<br>2、nsqd优先采用内存存储消息，当堆积的消息超过配置的最大内存消息数时则会进行持久化存储，目前nsq基于文件系统实现了一个先进先出的队列，源码地址：<a href="http://github.com/go-diskqueue">github.com/go-diskqueue</a></p>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nsq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列NSQ源码分析（二）：go-nsq</title>
      <link href="/2020/04/14/nsq-1/"/>
      <url>/2020/04/14/nsq-1/</url>
      
        <content type="html"><![CDATA[<p>本篇为NSQ源码分析的第二篇，主要分析nsq的客户端源码，即go-nsq。文章主要分为3个部分，第一部分主要讲述代码的整体架构设计以及一些配置项；第二部分结合源码分析<em><strong>生产者</strong></em>的整个生命周期；第三部分结合源码分析<em><strong>消费者</strong></em>的整个生命周期。</p><a id="more"></a><h2 id="代码架构">代码架构</h2><h3 id="整体设计">整体设计</h3><p>先上两个图：<br><img src="/images/go-nsq.jpg" alt> <img src="/images/go-nsq-architecture.png" alt><br>上面左图列出了<code>go-nsq</code>客户端包中的所有文件，右图是我整理的代码架构设计图，左图中的核心文件基本在右图中都有所体现。从右图可以看出，整体结构大致可以分为两层，上层的话主要对外暴露了两个概念：生产者和消费者；下层主要涉及与nsqd的连接以及协议处理；其中生产者和消费者没有直接的交互，两者只与底层连接进行通信，通过command的形式发送请求，以delegate的形式接收server端的响应，message也就是以这种方式传达给消费者的，同时message也将底层连接绑定为它的delegate，通过这种方式来进行消息的requeue，即重发（消息处理失败时会触发）。</p><h3 id="配置项介绍">配置项介绍</h3><p>我们使用各种第三方组件时通常都会传入一些配置项进行初始化，nsq也不例外，上图中没有将config配置标记出来，但不代表它不重要。在深入了解生产者、消费者源码之前，这里有必要单独对config中包含的配置项做一个简单的介绍。</p><pre><code class="language-go">// Config is a struct of NSQ options//// The only valid way to create a Config is via NewConfig, using a struct literal will panic.// After Config is passed into a high-level type (like Consumer, Producer, etc.) the values are no// longer mutable (they are copied).// Use Set(option string, value interface{}) as an alternate way to set parameters// 这里主要说明的是Config是以结构体的形式存在，同时它只能通过NewConfig方法进行创建，不能以字面量的形式直接创建。// 当Config被传入生产者或消费者来进行初始化的时候，Config不再可变，因为这时Config已经被生产者和消费者复制了一份type Config struct {// 用来判断配置是否已经初始化，通过NewConfig方法创建的Config该字段为true，如果直接用字面量创建的话该字段为false，因为是未导出的，// 初始化生产者和消费者时如果为false会直接panicinitialized bool// 用来设置配置项的默认值configHandlers []configHandler // 建立TCP连接的超时时间DialTimeout time.Duration `opt:&quot;dial_timeout&quot; default:&quot;1s&quot;`// TCP连接的读写超时时间ReadTimeout  time.Duration `opt:&quot;read_timeout&quot; min:&quot;100ms&quot; max:&quot;5m&quot; default:&quot;60s&quot;`WriteTimeout time.Duration `opt:&quot;write_timeout&quot; min:&quot;100ms&quot; max:&quot;5m&quot; default:&quot;1s&quot;`// 建立TCP连接的本地地址LocalAddr net.Addr `opt:&quot;local_addr&quot;`// 消费者轮询lookupd的时间间隔，来获取指定topic最新的生产者nsqd实例地址，当消费者时直连nsqd的时候，此配置项表示重连的间隔时间LookupdPollInterval time.Duration `opt:&quot;lookupd_poll_interval&quot; min:&quot;10ms&quot; max:&quot;5m&quot; default:&quot;60s&quot;`// 当多个消费者重启的时候，会等待一个随机因子的时间，然后再发送请求，用来减少并发的请求量LookupdPollJitter   float64       `opt:&quot;lookupd_poll_jitter&quot; min:&quot;0&quot; max:&quot;1&quot; default:&quot;0.3&quot;`// 消息处理失败时重新入队的最大延迟时间MaxRequeueDelay     time.Duration `opt:&quot;max_requeue_delay&quot; min:&quot;0&quot; max:&quot;60m&quot; default:&quot;15m&quot;`// 消息处理失败时重新入队的延迟时间DefaultRequeueDelay time.Duration `opt:&quot;default_requeue_delay&quot; min:&quot;0&quot; max:&quot;60m&quot; default:&quot;90s&quot;`// 退避的策略，NSQ采用的PUSH模型，因此需要有一定的策略来进行流量控制BackoffStrategy BackoffStrategy `opt:&quot;backoff_strategy&quot; default:&quot;exponential&quot;`// 退避的最大时间，设置为0表示不进行退避MaxBackoffDuration time.Duration `opt:&quot;max_backoff_duration&quot; min:&quot;0&quot; max:&quot;60m&quot; default:&quot;2m&quot;`// 退避的时间单位BackoffMultiplier time.Duration `opt:&quot;backoff_multiplier&quot; min:&quot;0&quot; max:&quot;60m&quot; default:&quot;1s&quot;`// 消费者处理一条消息的最大尝试次数MaxAttempts uint16 `opt:&quot;max_attempts&quot; min:&quot;0&quot; max:&quot;65535&quot; default:&quot;5&quot;`// rdy的闲置超时时间，意思是消费者与指定nsqd实例对应的连接上没有消息到来的闲置时间LowRdyIdleTimeout time.Duration `opt:&quot;low_rdy_idle_timeout&quot; min:&quot;1s&quot; max:&quot;5m&quot; default:&quot;10s&quot;`// 距上一次发送rdy的超时时间LowRdyTimeout time.Duration `opt:&quot;low_rdy_timeout&quot; min:&quot;1s&quot; max:&quot;5m&quot; default:&quot;30s&quot;`// 消费者重新计算各连接rdy数的时间间隔RDYRedistributeInterval time.Duration `opt:&quot;rdy_redistribute_interval&quot; min:&quot;1ms&quot; max:&quot;5s&quot; default:&quot;5s&quot;`// 用来标识客户端// UserAgent is in the spirit of HTTP (default: &quot;&lt;client_library_name&gt;/&lt;version&gt;&quot;)ClientID  string `opt:&quot;client_id&quot;` // (defaults: short hostname)Hostname  string `opt:&quot;hostname&quot;`UserAgent string `opt:&quot;user_agent&quot;`// 心跳包时间间隔，必须小于读超时时间HeartbeatInterval time.Duration `opt:&quot;heartbeat_interval&quot; default:&quot;30s&quot;`// 采样率，设置后只有一定比例的消息会发送给该客户端，比如设置为10，那么本来会发送100条消息给你，现在只会采样10条发给你SampleRate int32 `opt:&quot;sample_rate&quot; min:&quot;0&quot; max:&quot;99&quot;`// TLS配置TlsV1     bool        `opt:&quot;tls_v1&quot;`TlsConfig *tls.Config `opt:&quot;tls_config&quot;`// 消息压缩配置项Deflate      bool `opt:&quot;deflate&quot;`DeflateLevel int  `opt:&quot;deflate_level&quot; min:&quot;1&quot; max:&quot;9&quot; default:&quot;6&quot;`Snappy       bool `opt:&quot;snappy&quot;`// 缓冲大小，nsq服务端会为客户端连接设置一个缓冲buffer，用来缓冲消息OutputBufferSize int64 `opt:&quot;output_buffer_size&quot; default:&quot;16384&quot;`// 缓冲刷新的超时时间，超过该时间间隔后缓冲的消息会直接发送给客户端，设置为0表示不使用缓冲，需要注意的是，缓冲超时时间设置较小会对// CPU产生比较大的影响OutputBufferTimeout time.Duration `opt:&quot;output_buffer_timeout&quot; default:&quot;250ms&quot;`// 客户端最大的并发消息处理数量，此配置项比较重要，稍后讲消费者的时候会详细分析MaxInFlight int `opt:&quot;max_in_flight&quot; min:&quot;0&quot; default:&quot;1&quot;`// 用于服务端确认该条消息超时的时间，即超过该时间服务端则认为超时，会重发MsgTimeout time.Duration `opt:&quot;msg_timeout&quot; min:&quot;0&quot;`// 用于认证的密钥AuthSecret string `opt:&quot;auth_secret&quot;`}</code></pre><h2 id="生产者的视角">生产者的视角</h2><h3 id="生产者实例创建">生产者实例创建</h3><p>与生产者相关的代码主要在<code>producer.go</code>文件中，其中<code>Producer</code>结构体即为生产者对象的结构，如下：</p><pre><code class="language-go">type Producer struct {id     int64        //实例idaddr   string       //nsqd地址conn   producerConn //以接口的形式持有的底层连接config Config       //配置，各项含义上面已有介绍logger   []logger      //用来打印日志的实例对象logLvl   LogLevel      //日志等级logGuard sync.RWMutex  //设置日志等级和实例对象时需要加锁responseChan chan []byte  //接收响应的管道errorChan    chan []byte  //接收错误的管道closeChan    chan int     //接收关闭信号的管道transactionChan chan *ProducerTransaction   //接收发消息任务的管道transactions    []*ProducerTransaction      //当前发送中的消息state           int32                       //当前状态，states.go中有定义concurrentProducers int32           //当前并发发送消息的生产者数量stopFlag            int32           //停止标识exitChan            chan int        //接收退出信号的管道wg                  sync.WaitGroupguard               sync.Mutex}</code></pre><p>对象中的各个字段含义在上面都进行了注释，接下来我们看下创建生产者实例的方法：<code>NewProducer</code>，该方法同样位于<code>producer.go</code>文件中，如下：</p><pre><code class="language-go">func NewProducer(addr string, config *Config) (*Producer, error) {config.assertInitialized()err := config.Validate()if err != nil {return nil, err}p := &amp;Producer{id: atomic.AddInt64(&amp;instCount, 1),addr:   addr,config: *config,logger: make([]logger, int(LogLevelMax+1)),logLvl: LogLevelInfo,transactionChan: make(chan *ProducerTransaction),exitChan:        make(chan int),responseChan:    make(chan []byte),errorChan:       make(chan []byte),}// Set default logger for all log levelsl := log.New(os.Stderr, &quot;&quot;, log.Flags())for index, _ := range p.logger {p.logger[index] = l}return p, nil}</code></pre><p>从上述代码中可以看出，生产者的创建过程基本就是：</p><ol><li>验证传入的配置</li><li>实例化生产者对应的结构体</li><li>设置日志实例</li><li>返回生产者实例</li></ol><h3 id="发送消息">发送消息</h3><p>了解了生产者创建的过程之后，我们来看一下生产者是怎么发送消息的。对外暴露的发送消息的方法有6个，如下：</p><pre><code class="language-go">// 异步发送func (w *Producer) PublishAsync(topic string, body []byte, doneChan chan *ProducerTransaction,args ...interface{}) error {return w.sendCommandAsync(Publish(topic, body), doneChan, args)}// 异步发送，支持批量func (w *Producer) MultiPublishAsync(topic string, body [][]byte, doneChan chan *ProducerTransaction,args ...interface{}) error {cmd, err := MultiPublish(topic, body)if err != nil {return err}return w.sendCommandAsync(cmd, doneChan, args)}// 同步发送func (w *Producer) Publish(topic string, body []byte) error {return w.sendCommand(Publish(topic, body))}// 同步发送，支持批量func (w *Producer) MultiPublish(topic string, body [][]byte) error {cmd, err := MultiPublish(topic, body)if err != nil {return err}return w.sendCommand(cmd)}// 延迟发送，同步调用func (w *Producer) DeferredPublish(topic string, delay time.Duration, body []byte) error {return w.sendCommand(DeferredPublish(topic, delay, body))}// 延迟发送，异步调用func (w *Producer) DeferredPublishAsync(topic string, delay time.Duration, body []byte,doneChan chan *ProducerTransaction, args ...interface{}) error {return w.sendCommandAsync(DeferredPublish(topic, delay, body), doneChan, args)}</code></pre><p>从上面6个方法中的具体内容可以看出，发送消息基本上分为两步：</p><ol><li>构造command</li><li>调用sendCommand或sendCommandAsync</li></ol><p>我们先来看看构造command的过程，command的定义与相关方法位于<code>command.go</code>文件中，这里主要介绍它的结构以及与发送消息相关的方法，如下：</p><pre><code class="language-go">type Command struct {Name   []byteParams [][]byteBody   []byte}func Publish(topic string, body []byte) *Command {var params = [][]byte{[]byte(topic)}return &amp;Command{[]byte(&quot;PUB&quot;), params, body}}func DeferredPublish(topic string, delay time.Duration, body []byte) *Command {var params = [][]byte{[]byte(topic), []byte(strconv.Itoa(int(delay / time.Millisecond)))}return &amp;Command{[]byte(&quot;DPUB&quot;), params, body}}func MultiPublish(topic string, bodies [][]byte) (*Command, error) {var params = [][]byte{[]byte(topic)}num := uint32(len(bodies))bodySize := 4for _, b := range bodies {bodySize += len(b) + 4}body := make([]byte, 0, bodySize)buf := bytes.NewBuffer(body)err := binary.Write(buf, binary.BigEndian, &amp;num)if err != nil {return nil, err}for _, b := range bodies {err = binary.Write(buf, binary.BigEndian, int32(len(b)))if err != nil {return nil, err}_, err = buf.Write(b)if err != nil {return nil, err}}return &amp;Command{[]byte(&quot;MPUB&quot;), params, buf.Bytes()}, nil}</code></pre><p>可以看到，构造command的过程就是填充Command结构体，包含了命令名称，命令参数（topic、延迟发送的时间），具体消息内容三个部分。<br>我们再来看看发送命令的过程，即调用sendCommand或sendCommandAsync，这两个方法位于<code>producer.go</code>文件中，如下：</p><pre><code class="language-go">func (w *Producer) sendCommand(cmd *Command) error {doneChan := make(chan *ProducerTransaction)err := w.sendCommandAsync(cmd, doneChan, nil)if err != nil {close(doneChan)return err}t := &lt;-doneChanreturn t.Error}func (w *Producer) sendCommandAsync(cmd *Command, doneChan chan *ProducerTransaction,args []interface{}) error {// keep track of how many outstanding producers we're dealing with// in order to later ensure that we clean them all up...atomic.AddInt32(&amp;w.concurrentProducers, 1)defer atomic.AddInt32(&amp;w.concurrentProducers, -1)if atomic.LoadInt32(&amp;w.state) != StateConnected {err := w.connect()if err != nil {return err}}t := &amp;ProducerTransaction{cmd:      cmd,doneChan: doneChan,Args:     args,}select {case w.transactionChan &lt;- t:case &lt;-w.exitChan:return ErrStopped}return nil}</code></pre><p>可以看到，sendCommand最终也是调用了sendCommandAsync，先看下sendCommandAsync方法的三个参数，第一个参数是command，也就是我们上一步构造的命令；第二个参数是一个管道，这个主要是用来支持异步调用，我们发送消息时可以单独创建一个管道，开启一个goroutine来异步接收管道中的返回结果，sendCommandAsync会通过管道将异步调用的结果发送给调用方，当处于同步调用时，我们可以看到sendCommand中内部自己构造了一个channel，然后调用sendCommandAsync，接着等待channel返回值，因为sendCommand中并没有单独开启一个goroutine去异步接收，从而实现了同步调用的效果；第三个参数是异步调用时用户自定义的参数。了解了参数之后，我们来看下函数具体的执行过程：</p><ol><li>调用atomic.AddInt32原子性的增加当前并发的生产者数量，通过defer在函数执行完后减掉刚刚递增的数量</li><li>判断当前生产者的连接是否有效，如果未连接则调用connect()方法建立连接</li><li>构造发送消息的任务并通过管道发送</li></ol><p>这里我们会有个很直接的疑问，发送消息的任务通过管道发送之后，谁来处理呢？谁来真正调用底层的连接进行消息的发送呢？答案就在第二步中的connect()方法中，我们不妨来看下connect()方法：</p><pre><code class="language-go">func (w *Producer) connect() error {w.guard.Lock()defer w.guard.Unlock()w.conn = NewConn(w.addr, &amp;w.config, &amp;producerConnDelegate{w})_, err := w.conn.Connect()if err != nil {w.conn.Close()return err}atomic.StoreInt32(&amp;w.state, StateConnected)w.closeChan = make(chan int)w.wg.Add(1)go w.router()return nil}</code></pre><p>上面的connect方法经过了处理，部分无关紧要的内容已经被略去，可以看到主要流程就是对conn字段的初始化，并调用conn.connect，然后go出一个协程执行w.router()，我们重点看下w.router的具体内容：</p><pre><code class="language-go">func (w *Producer) router() {for {select {case t := &lt;-w.transactionChan:w.transactions = append(w.transactions, t)err := w.conn.WriteCommand(t.cmd)if err != nil {w.log(LogLevelError, &quot;(%s) sending command - %s&quot;, w.conn.String(), err)w.close()}case data := &lt;-w.responseChan:w.popTransaction(FrameTypeResponse, data)case data := &lt;-w.errorChan:w.popTransaction(FrameTypeError, data)case &lt;-w.closeChan:goto exitcase &lt;-w.exitChan:goto exit}}exit:w.transactionCleanup()w.wg.Done()w.log(LogLevelInfo, &quot;exiting router&quot;)}</code></pre><p>这下真相大白了，这个goroutine创建了一个死循环，一直接收transactionChan管道里的任务，并通过底层的连接进行发送，可以看到select还有一些其他的case，如responseChan、errorChan，主要还是接收发送消息后的服务端响应以及处理一些错误。</p><h3 id="连接处理">连接处理</h3><p>接下来我们讲讲连接处理，这一块的逻辑主要从connect()开始，上面我们分析发送消息的源码时有看到，调用sendCommandAsync时如果producer的状态不等于StateConnected（已连接），则会调用connect()，这里用到了一个lazy connect on publish的技巧，即当发送消息时才真正建立连接。同时上面也有讲到，connect的主要流程是调用NewConn函数对conn字段进行初始化，并调用conn.connect建立连接，我们先来看下NewConn函数的源码：</p><pre><code class="language-go">func NewConn(addr string, config *Config, delegate ConnDelegate) *Conn {return &amp;Conn{addr: addr,   //地址config:   config,   //配置delegate: delegate, //委托者模式的需要实现的接口maxRdyCount:      2500,  //最大并发消息数lastMsgTimestamp: time.Now().UnixNano(), //上一次收到消息时间cmdChan:         make(chan *Command),     //接收命令的管道msgResponseChan: make(chan *msgResponse), //接收消息响应的管道exitChan:        make(chan int),          //退出信号的管道drainReady:      make(chan int),          //清空当前未处理的消息}}</code></pre><p>先来看看NewConn调用，前两个参数是地址和配置项，前面已有介绍，我们看下第3个参数：delegate，这里主要使用了委托者模式，由producer实现ConnDelegate中相应的接口，Conn在接收到服务端发送回来的响应时会通过这种委托者的模式调用delegate对应的方法，我们可以看到上面生产者调用NewConn时传递的第3个参数具体内容为<code>&amp;producerConnDelegate{w}</code>，这个结构体主要实现了一些生产者所关心的内容：服务端响应、连接错误、心跳等，其他接口都为空实现，如下：</p><pre><code class="language-go">type producerConnDelegate struct {w *Producer}func (d *producerConnDelegate) OnResponse(c *Conn, data []byte)       { d.w.onConnResponse(c, data) }func (d *producerConnDelegate) OnError(c *Conn, data []byte)          { d.w.onConnError(c, data) }func (d *producerConnDelegate) OnMessage(c *Conn, m *Message)         {}func (d *producerConnDelegate) OnMessageFinished(c *Conn, m *Message) {}func (d *producerConnDelegate) OnMessageRequeued(c *Conn, m *Message) {}func (d *producerConnDelegate) OnBackoff(c *Conn)                     {}func (d *producerConnDelegate) OnContinue(c *Conn)                    {}func (d *producerConnDelegate) OnResume(c *Conn)                      {}func (d *producerConnDelegate) OnIOError(c *Conn, err error)          { d.w.onConnIOError(c, err) }func (d *producerConnDelegate) OnHeartbeat(c *Conn)                   { d.w.onConnHeartbeat(c) }func (d *producerConnDelegate) OnClose(c *Conn)                       { d.w.onConnClose(c) }</code></pre><p>接着我们再来看看conn.Connect()的具体实现，如下：</p><pre><code class="language-go">func (c *Conn) Connect() (*IdentifyResponse, error) {dialer := &amp;net.Dialer{LocalAddr: c.config.LocalAddr,Timeout:   c.config.DialTimeout,}conn, err := dialer.Dial(&quot;tcp&quot;, c.addr)if err != nil {return nil, err}c.conn = conn.(*net.TCPConn)c.r = connc.w = conn_, err = c.Write(MagicV2)if err != nil {c.Close()return nil, fmt.Errorf(&quot;[%s] failed to write magic - %s&quot;, c.addr, err)}resp, err := c.identify()if err != nil {return nil, err}if resp != nil &amp;&amp; resp.AuthRequired {if c.config.AuthSecret == &quot;&quot; {c.log(LogLevelError, &quot;Auth Required&quot;)return nil, errors.New(&quot;Auth Required&quot;)}err := c.auth(c.config.AuthSecret)if err != nil {c.log(LogLevelError, &quot;Auth Failed %s&quot;, err)return nil, err}}c.wg.Add(2)atomic.StoreInt32(&amp;c.readLoopRunning, 1)go c.readLoop()go c.writeLoop()return resp, nil}</code></pre><p>整个函数主要分为4个流程：</p><ol><li>建立tcp连接</li><li>发送版本号：MagicV2</li><li>调用identify，将客户端的一些配置项传递给服务端，同时根据服务端响应进行一些配置项的设置</li><li>开启I/O循环<br>前3步为nsq客户端与服务端建立完整连接的标准流程，没有特别的东西，我们重点关注I/O循环这一块，先来看下readLoop：</li></ol><pre><code class="language-go">func (c *Conn) readLoop() {delegate := &amp;connMessageDelegate{c}for {frameType, data, err := ReadUnpackedResponse(c)if err != nil {if !strings.Contains(err.Error(), &quot;use of closed network connection&quot;) {c.delegate.OnIOError(c, err)}goto exit}if frameType == FrameTypeResponse &amp;&amp; bytes.Equal(data, []byte(&quot;_heartbeat_&quot;)) {c.delegate.OnHeartbeat(c)err := c.WriteCommand(Nop())if err != nil {c.delegate.OnIOError(c, err)goto exit}continue}switch frameType {case FrameTypeResponse:c.delegate.OnResponse(c, data)case FrameTypeMessage:msg, err := DecodeMessage(data)if err != nil {c.delegate.OnIOError(c, err)goto exit}msg.Delegate = delegatemsg.NSQDAddress = c.String()c.delegate.OnMessage(c, msg)case FrameTypeError:c.delegate.OnError(c, data)default:c.delegate.OnIOError(c, fmt.Errorf(&quot;unknown frame type %d&quot;, frameType))}}}</code></pre><p>readLoop先调用ReadUnpackedResponse根据协议读取服务端发送过来的网络包，该函数具体代码在<code>protocol.go</code>文件中，主要是对协议上的处理，这里不做细讲，我们继续看接下来的逻辑，接着判断包的类型是不是心跳包，是的话直接返回响应，无须上层的生产者或消费者处理；接着是一个switch分支，有3个case：</p><ol><li>包类型为FrameTypeResponse时，表示服务端对之前客户端发送命令的响应，比如生产者发送消息的响应</li><li>包类型为FrameTypeMessage时，表示收到消息，主要是消费者的场景会用到</li><li>包类型为FrameTypeError时，表示服务端处理发生错误<br>readLoop的内容基本就是处理服务端心跳包、发回的消息、响应和错误，并调用委托者delegate通知上层的生产者或消费者，接下来我们再来分析writeLoop的源码：</li></ol><pre><code class="language-go">func (c *Conn) writeLoop() {for {select {case &lt;-c.exitChan:close(c.drainReady)goto exitcase cmd := &lt;-c.cmdChan:err := c.WriteCommand(cmd)if err != nil {c.close()continue}case resp := &lt;-c.msgResponseChan:msgsInFlight := atomic.AddInt64(&amp;c.messagesInFlight, -1)if resp.success {c.delegate.OnMessageFinished(c, resp.msg)c.delegate.OnResume(c)} else {c.delegate.OnMessageRequeued(c, resp.msg)if resp.backoff {c.delegate.OnBackoff(c)} else {c.delegate.OnContinue(c)}}err := c.WriteCommand(resp.cmd)if err != nil {c.close()continue}if msgsInFlight == 0 &amp;&amp;atomic.LoadInt32(&amp;c.closeFlag) == 1 {c.close()continue}}}exit:c.wg.Done()}</code></pre><p>可以看到，writeLoop通过for循环加select处理三种场景：</p><ol><li>接收退出信号，清理未处理的消息</li><li>从命令管道接收命令，目前这个管道只有conn的onMessageTouch方法在使用，该方法又由message的公共方法Touch调用，主要用来发送touch命令，即重置消息的超时时间</li><li>从消息处理结果管道接收结果，将结果发送给nsqd服务端，主要用来通知nsqd服务端该消息是消费完成还是需要重新入队<br>总结一下writeLoop的内容基本就是将消息处理的结果通过命令的形式发送给nsqd服务端，如重置消息超时时间、消息完成、消息重新入队等。<br>关于连接处理这一块我们再来看看一些异常情况下的处理流程，异常处理的代码主要就在上述两个I/O循环中，可以看到当对网络连接进行读写时发生错误会触发OnIOError函数，该函数再通过delegate将错误通知给上层的producer或consumer，查看producer的delegate可以发现，当OnIOError触发时会调用producer的onConnIOError方法，该方法代码如下：</li></ol><pre><code class="language-go">func (w *Producer) onConnIOError(c *Conn, err error)    { w.close() }func (w *Producer) close() {if !atomic.CompareAndSwapInt32(&amp;w.state, StateConnected, StateDisconnected) {return}w.conn.Close()go func() {// we need to handle this in a goroutine so we don't// block the caller from making progressw.wg.Wait()atomic.StoreInt32(&amp;w.state, StateInit)}()}</code></pre><p>可以看到producer的onConnIOError方法只是调用了producer自身的close，close判断当前状态是否是已连接状态，然后将它持有的底层连接关闭，即调用conn.Close，我们继续跟踪conn.Close的具体代码，如下：</p><pre><code class="language-go">func (c *Conn) Close() error {atomic.StoreInt32(&amp;c.closeFlag, 1)if c.conn != nil &amp;&amp; atomic.LoadInt64(&amp;c.messagesInFlight) == 0 {return c.conn.CloseRead()}return nil}</code></pre><p>调用Close方法之后，会将closeFlag置为1，也就是将连接标记为关闭，标记为关闭后我们还有两个I/O循环未退出，即上述的readLoop和writeLoop，我们分别分析一下，首先来看readLoop，分析readLoop代码可以看到在读循环中会判断closeFlag，如果已经标记为关闭时会直接调用goto退出循环，如果此时没有正在处理的消息则直接调用close方法，该方法会关闭底层tcp连接并通知writeLoop也退出；接着我们分析writeLoop，当writeLoop发生写错误时，也会直接调用close方法关闭tcp连接，关于close方法这里不做详细描述，主要还是清理掉正在处理的消息并关闭tcp连接</p><h3 id="退出">退出</h3><p>生产者的退出是通过调用producer的Stop方法来完成的，如下：</p><pre><code class="language-go">func (w *Producer) Stop() {w.guard.Lock()if !atomic.CompareAndSwapInt32(&amp;w.stopFlag, 0, 1) {w.guard.Unlock()return}w.log(LogLevelInfo, &quot;stopping&quot;)close(w.exitChan)w.close()w.guard.Unlock()w.wg.Wait()}</code></pre><p>上述流程主要是关闭exitChan管道来通知router循环退出，然后调用close关闭连接，close方法的流程已在上面连接处理中描述过，这里就不进行过多描述了，至此，我们已经分析完了整个生产者的生命周期，主要包括创建实例、发送消息、连接处理、退出等流程，接下来我们换一个角度，看看消费者的处理流程又是怎样的。</p><h2 id="消费者的视角">消费者的视角</h2><h3 id="实例创建">实例创建</h3><p>与消费者相关的代码主要在<code>consumer.go</code>文件中，其中<code>Consumer</code>结构体即为消费者对象的结构，如下：</p><pre><code class="language-go">type Consumer struct {messagesReceived uint64   //收到的消息总数，用于数据统计messagesFinished uint64   //处理成功的消息总数，用于数据统计messagesRequeued uint64   //重新入队的消息总数，用于数据统计totalRdyCount    int64    //当前实际的可处理并发消息数量backoffDuration  int64    //退避的时间，用于流量控制backoffCounter   int32    //退避的次数，用于流量控制maxInFlight      int32    //消费者可处理的最大并发消息数量mtx sync.RWMutex    //日志相关logger   loggerlogLvl   LogLevellogGuard sync.RWMutexbehaviorDelegate interface{}  //通过该delegate修改consumer的行为，目前可以用来过滤部分nsqd实例地址id      int64   //消费者实例idtopic   string  //订阅的topicchannel string  //订阅的channelconfig  Config  //配置项rngMtx sync.Mutexrng    *rand.RandneedRDYRedistributed int32  //是否需要更新当前每个连接可接收的消息数量backoffMtx sync.MutexincomingMessages chan *Message    //接收消息的管道rdyRetryMtx    sync.MutexrdyRetryTimers map[string]*time.Timer  //需要更新rdy，但是触发了maxInFlight的限制，只能开启定时器稍后重试pendingConnections map[string]*Conn    //正在与nsqd建立连接的connconnections        map[string]*Conn    //已经与nsqd建立连接的connnsqdTCPAddrs []string  //nsqd实例地址lookupdRecheckChan chan int  //传递重新查询lookupd信号的管道lookupdHTTPAddrs   []string  //nsqlookupd的实例地址lookupdQueryIndex  int       //下一次轮询的nsqlookupd地址wg              sync.WaitGrouprunningHandlers int32      //当前并发处理器的数量stopFlag        int32      //退出标识connectedFlag   int32      //连接标识stopHandler     sync.Once  //用于通知并发消息处理器退出exitHandler     sync.Once  //用于通知内部lookupLoop和rdyLoop退出循环StopChan chan int  //开发者用来接收消费者退出完成信号的管道exitChan chan int  //内部使用的退出信号管道}</code></pre><p>对象中的各个字段含义在上面都进行了注释，接下来我们看下创建消费者实例的方法：<code>NewConsumer</code>，该方法同样位于<code>consumer.go</code>文件中，如下：</p><pre><code class="language-go">func NewConsumer(topic string, channel string, config *Config) (*Consumer, error) {config.assertInitialized()if err := config.Validate(); err != nil {return nil, err}if !IsValidTopicName(topic) {return nil, errors.New(&quot;invalid topic name&quot;)}if !IsValidChannelName(channel) {return nil, errors.New(&quot;invalid channel name&quot;)}r := &amp;Consumer{id: atomic.AddInt64(&amp;instCount, 1),topic:   topic,channel: channel,config:  *config,logger:      log.New(os.Stderr, &quot;&quot;, log.Flags()),logLvl:      LogLevelInfo,maxInFlight: int32(config.MaxInFlight),incomingMessages: make(chan *Message),rdyRetryTimers:     make(map[string]*time.Timer),pendingConnections: make(map[string]*Conn),connections:        make(map[string]*Conn),lookupdRecheckChan: make(chan int, 1),rng: rand.New(rand.NewSource(time.Now().UnixNano())),StopChan: make(chan int),exitChan: make(chan int),}r.wg.Add(1)go r.rdyLoop()return r, nil}</code></pre><p>NewConsumer函数流程首先验证配置，然后实例化消费者结构体，最后开启了rdyLoop循环，该循环主要用来调整rdy的数值。<br>创建好实例之后，我们需要调用AddHandler或AddConcurrentHandlers来添加消息处理的handler，handler是一个接口类型，如下：</p><pre><code class="language-go">type Handler interface {HandleMessage(message *Message) error}</code></pre><p>开发者只需要将实现了该接口的对象通过AddHandler或AddConcurrentHandlers添加即可。实例化并添加handler之后，我们需要调用ConnectToNSQLookupds或ConnectToNSQDs来创建连接并接收消息，这里分别介绍一下两种方式的区别：</p><ol><li>当我们通过ConnectToNSQLookupds来连接时，会先通过http的方式查询NSQLookupd实例当前指定topic存在哪些nsqd实例，然后通过ConnectToNSQD分别建立连接，同时启动一个额外的goroutine去定时轮询对应的NSQLookupd实例，这样就实现了动态发现指定topic的nsqd实例，具体可查看lookupdLoop方法的代码，这里不详细描述</li><li>当我们通过ConnectToNSQDs来连接时，也就是采用直连的方式，该方法会实例化底层连接，然后建立与nsqd的tcp连接，发送订阅命令<br>在生产环境中推荐使用第一种方式，支持nsqd实例的动态发现</li></ol><h3 id="消息处理">消息处理</h3><p>接下来我们看看消息处理的过程，上面有提到，我们可以通过AddHandler或AddConcurrentHandlers来添加消息处理器，也就是实现了Handler方法的对象，当然函数也可以，go-nsq提供了HandlerFunc进行包装，我们看看AddHandler和AddConcurrentHandlers的具体内容：</p><pre><code class="language-go">func (r *Consumer) AddHandler(handler Handler) {r.AddConcurrentHandlers(handler, 1)}func (r *Consumer) AddConcurrentHandlers(handler Handler, concurrency int) {if atomic.LoadInt32(&amp;r.connectedFlag) == 1 {panic(&quot;already connected&quot;)}atomic.AddInt32(&amp;r.runningHandlers, int32(concurrency))for i := 0; i &lt; concurrency; i++ {go r.handlerLoop(handler)}}func (r *Consumer) handlerLoop(handler Handler) {r.log(LogLevelDebug, &quot;starting Handler&quot;)for {message, ok := &lt;-r.incomingMessagesif !ok {goto exit}if r.shouldFailMessage(message, handler) {message.Finish()continue}err := handler.HandleMessage(message)if err != nil {r.log(LogLevelError, &quot;Handler returned error (%s) for msg %s&quot;, err, message.ID)if !message.IsAutoResponseDisabled() {message.Requeue(-1)}continue}if !message.IsAutoResponseDisabled() {message.Finish()}}exit:r.log(LogLevelDebug, &quot;stopping Handler&quot;)if atomic.AddInt32(&amp;r.runningHandlers, -1) == 0 {r.exit()}}</code></pre><p>可以看到AddHandler内部也是通过调用AddConcurrentHandlers来添加消息处理器，并发数设置的1，AddConcurrentHandlers则会根据传入的concurrency数量来创建一个或多个goroutine来执行handlerLoop，handlerLoop则是对应的消息处理流程，它负责从incomingMessages管道接收消息，然后调用消息处理器的HandleMessage接口，当HandleMessage返回的error不为空时，则会将消息重新入队，即message.Requeue，否则调用message.Finish来通知nsqd消息已处理完成。</p><h3 id="流量控制">流量控制</h3><p>因为nsq采用的是push模型，消息由服务端推送给消费者，这个过程中可能出现消费者对于消息处理不过来的情况，那么就需要有一定的流量控制策略，接下来我们就来具体看看消费者如何实现流量控制的：</p><ol><li>首先在NSQ中有一个RDY的概念，本质上就是客户端的一个流量控制，当消费者客户端连接nsqd然后订阅某个topic后，会先发送RDY=0，这意味着不会有消息发送给客户端，当客户端准备好接收消息时会更新RDY的值（比如100），然后发送给nsqd服务端，接着服务端就可以将消息推送给客户端了；</li><li>因为RDY参数是内部实现的概念，对于使用者来说，我们可以通过配置Max-In-Flight选项来限制客户端的最大消费能力。那RDY和Max-In-Flight有什么关系呢？这里有必要说明一下，RDY是消费者客户端与指定nsqd连接的流量控制值，而Max-In-Flight是消费者客户端整体的流量控制值，即<code>RDY = Max-In-Flight / len(conns)</code>，conns就是消费者客户端与nsqd的连接，也就是说多个连接会平分Max-In-Flight的配置值，来达到整体流量控制的目的；</li><li>最后需要说明的是，当消息处理失败时，会将消息重新入队<code>message.Requeue</code>，此时会触发流量控制，这种场景下的流量控制是通过退避算法实现的，代码中使用backoff来体现，具体内容就是计算退避时间，将各个连接的RDY置为0，表示不再接收消息，等待退避时间完成后，随机选取一个连接将RDY置为1，看是否能够成功处理消息，成功则将各个连接的RDY重新恢复为正常值，失败则继续触发退避，将各连接RDY置为0，这里有一点需要注意，随机选取的连接RDY置为1后，可能没有消息发送过来，这时可能其他连接存在消息可以接收，但RDY却为0，导致无法及时退出整个退避的过程，这个问题是通过rdyLoop解决的，rdyLoop会定时检查各个连接上次发送RDY的时间，如果刚才RDY置为1的连接在一定时间内未接收到消息，则会将此连接RDY置为0，重新随机选取连接。</li></ol><h3 id="退出-2">退出</h3><p>消费者的退出通过调用consumer.Stop：</p><pre><code class="language-go">func (r *Consumer) Stop() {if !atomic.CompareAndSwapInt32(&amp;r.stopFlag, 0, 1) {return}r.log(LogLevelInfo, &quot;stopping...&quot;)if len(r.conns()) == 0 {r.stopHandlers()} else {for _, c := range r.conns() {err := c.WriteCommand(StartClose())if err != nil {r.log(LogLevelError, &quot;(%s) error sending CLS - %s&quot;, c.String(), err)}}time.AfterFunc(time.Second*30, func() {// if we've waited this long handlers are blocked on processing messages// so we can't just stopHandlers (if any adtl. messages were pending processing// we would cause a panic on channel close)//// instead, we just bypass handler closing and skip to the final exitr.exit()})}}</code></pre><p>流程主要是将与各个nsqd实例的连接关闭，然后通过关闭接收消息的incomingMessages管道来通知当前并发的handlerLoop退出，接着关闭exitChan通知rdyLoop和lookupdLoop退出，最后关闭暴露给使用者的StopChan</p>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nsq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列NSQ源码分析（一）：概述</title>
      <link href="/2020/04/14/nsq-0/"/>
      <url>/2020/04/14/nsq-0/</url>
      
        <content type="html"><![CDATA[<p>本篇为NSQ源码分析的第一篇，主要讲述NSQ的一些基础概念以及整体架构、各组件功能</p><a id="more"></a><h2 id="基础概念">基础概念</h2><h3 id="topic、channel">topic、channel</h3><p>topic和channel是nsq中比较重要的两个概念，topic代表了某种类型的数据流，一个topic通常有1个或多个channel，每个channel都会收到发往这个topic的消息拷贝。同时，一个channel可以注册多个消费者，channel的消息会随机发送给其中一个消费者。如下图：<br><img src="/images/nsq.gif" alt></p><h3 id="nsq的消息投递模型和语义">nsq的消息投递模型和语义</h3><p>nsq采用的消息投递模型是<em><strong>push</strong></em>的方式，即消息会主动推送给消费者，同时通过超时重传和确认机制实现了<em><strong>最少一次</strong></em>的消息投递语义</p><h2 id="整体架构">整体架构</h2><p><img src="/images/nsq-architecture.png" alt></p><h3 id="各组件功能">各组件功能</h3><h4 id="nsqd">nsqd</h4><p>nsq消息队列实例，用来实现消息队列的核心功能，即消息的接收、发送、存储、topic、channel等关系的维护</p><h4 id="nsqlookupd">nsqlookupd</h4><p>用来实现消费者动态发现nsqd实例，消费者会定时轮询这个服务来获取当前生产指定topic的nsqd实例地址，同时nsqd实例也会定时上报实例信息到此服务。通过这种方式实现了消费者与生产者的解耦，消费者只需配置nsqlookupd实例的地址即可动态的发现指定topic的nsqd实例</p><h4 id="nsqadmin">nsqadmin</h4><p>nsq的web管理后台，用来查看当前nsq集群的统计信息并执行一些管理任务</p><hr><p>除了上面3个组件外，nsq官方还提供了一些命令行工具</p><ul><li>nsq_stat：将当前nsq的统计信息输出到标准输出</li><li>nsq_tail：将指定topic/channel中的消息消费掉并输出到标准输出</li><li>nsq_to_file：将指定topic/channel中的消息消费掉并输出到文件</li><li>nsq_to_http：将指定topic/channel中的消息消费掉并向指定的地址发送http请求</li><li>nsq_to_nsq：将指定topic/channel中的消息消费掉并重新发布到指定的nsq实例</li><li>to_nsq：从标准输入获取数据并发送到nsq实例中</li></ul>]]></content>
      
      
      <categories>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> nsq </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
